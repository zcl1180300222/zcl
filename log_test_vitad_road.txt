2024-09-23 15:24:17,356 - ==> Logging on master GPU: 0
2024-09-23 15:24:17,356 - ==> Running Trainer: ViTADTrainer
2024-09-23 15:24:17,356 - ==> Using GPU: [0] for Training
2024-09-23 15:24:17,356 - ==> Building model
2024-09-23 15:24:17,570 - Loading pretrained weights from url (https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth)
2024-09-23 15:24:17,613 - Resized position embedding: (14, 14) to (16, 16).
2024-09-23 15:24:17,969 - ==> Load checkpoint: /data/x2/ader/runs/ViTADTrainer_configs_vitad_vitad_mvtec_20240923-113201/net.pth
2024-09-23 15:24:18,407 - 
------------------------------------ ViTAD ------------------------------------
| module                            | #parameters or shape   | #flops       |
|:----------------------------------|:-----------------------|:-------------|
| model                             | 38.586M                | 9.668G       |
|  net_t                            |  21.689M               |  5.544G      |
|   net_t.cls_token                 |   (1, 1, 384)          |              |
|   net_t.pos_embed                 |   (1, 257, 384)        |              |
|   net_t.patch_embed.proj          |   0.295M               |   75.497M    |
|    net_t.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_t.patch_embed.proj.bias    |    (384,)              |              |
|   net_t.blocks                    |   21.294M              |   5.469G     |
|    net_t.blocks.0                 |    1.774M              |    0.456G    |
|     net_t.blocks.0.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm1.weight  |      (384,)            |              |
|      net_t.blocks.0.norm1.bias    |      (384,)            |              |
|     net_t.blocks.0.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.0.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.0.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.0.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.0.norm2.weight  |      (384,)            |              |
|      net_t.blocks.0.norm2.bias    |      (384,)            |              |
|     net_t.blocks.0.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.0.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.0.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.1                 |    1.774M              |    0.456G    |
|     net_t.blocks.1.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm1.weight  |      (384,)            |              |
|      net_t.blocks.1.norm1.bias    |      (384,)            |              |
|     net_t.blocks.1.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.1.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.1.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.1.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.1.norm2.weight  |      (384,)            |              |
|      net_t.blocks.1.norm2.bias    |      (384,)            |              |
|     net_t.blocks.1.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.1.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.1.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.2                 |    1.774M              |    0.456G    |
|     net_t.blocks.2.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm1.weight  |      (384,)            |              |
|      net_t.blocks.2.norm1.bias    |      (384,)            |              |
|     net_t.blocks.2.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.2.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.2.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.2.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.2.norm2.weight  |      (384,)            |              |
|      net_t.blocks.2.norm2.bias    |      (384,)            |              |
|     net_t.blocks.2.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.2.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.2.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.3                 |    1.774M              |    0.456G    |
|     net_t.blocks.3.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm1.weight  |      (384,)            |              |
|      net_t.blocks.3.norm1.bias    |      (384,)            |              |
|     net_t.blocks.3.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.3.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.3.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.3.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.3.norm2.weight  |      (384,)            |              |
|      net_t.blocks.3.norm2.bias    |      (384,)            |              |
|     net_t.blocks.3.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.3.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.3.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.4                 |    1.774M              |    0.456G    |
|     net_t.blocks.4.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm1.weight  |      (384,)            |              |
|      net_t.blocks.4.norm1.bias    |      (384,)            |              |
|     net_t.blocks.4.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.4.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.4.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.4.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.4.norm2.weight  |      (384,)            |              |
|      net_t.blocks.4.norm2.bias    |      (384,)            |              |
|     net_t.blocks.4.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.4.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.4.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.5                 |    1.774M              |    0.456G    |
|     net_t.blocks.5.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm1.weight  |      (384,)            |              |
|      net_t.blocks.5.norm1.bias    |      (384,)            |              |
|     net_t.blocks.5.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.5.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.5.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.5.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.5.norm2.weight  |      (384,)            |              |
|      net_t.blocks.5.norm2.bias    |      (384,)            |              |
|     net_t.blocks.5.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.5.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.5.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.6                 |    1.774M              |    0.456G    |
|     net_t.blocks.6.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm1.weight  |      (384,)            |              |
|      net_t.blocks.6.norm1.bias    |      (384,)            |              |
|     net_t.blocks.6.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.6.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.6.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.6.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.6.norm2.weight  |      (384,)            |              |
|      net_t.blocks.6.norm2.bias    |      (384,)            |              |
|     net_t.blocks.6.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.6.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.6.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.7                 |    1.774M              |    0.456G    |
|     net_t.blocks.7.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm1.weight  |      (384,)            |              |
|      net_t.blocks.7.norm1.bias    |      (384,)            |              |
|     net_t.blocks.7.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.7.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.7.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.7.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.7.norm2.weight  |      (384,)            |              |
|      net_t.blocks.7.norm2.bias    |      (384,)            |              |
|     net_t.blocks.7.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.7.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.7.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.8                 |    1.774M              |    0.456G    |
|     net_t.blocks.8.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm1.weight  |      (384,)            |              |
|      net_t.blocks.8.norm1.bias    |      (384,)            |              |
|     net_t.blocks.8.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.8.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.8.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.8.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.8.norm2.weight  |      (384,)            |              |
|      net_t.blocks.8.norm2.bias    |      (384,)            |              |
|     net_t.blocks.8.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.8.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.8.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.9                 |    1.774M              |    0.456G    |
|     net_t.blocks.9.norm1          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm1.weight  |      (384,)            |              |
|      net_t.blocks.9.norm1.bias    |      (384,)            |              |
|     net_t.blocks.9.attn           |     0.591M             |     0.152G   |
|      net_t.blocks.9.attn.qkv      |      0.444M            |      0.114G  |
|      net_t.blocks.9.attn.proj     |      0.148M            |      37.896M |
|     net_t.blocks.9.norm2          |     0.768K             |     0.493M   |
|      net_t.blocks.9.norm2.weight  |      (384,)            |              |
|      net_t.blocks.9.norm2.bias    |      (384,)            |              |
|     net_t.blocks.9.mlp            |     1.182M             |     0.303G   |
|      net_t.blocks.9.mlp.fc1       |      0.591M            |      0.152G  |
|      net_t.blocks.9.mlp.fc2       |      0.59M             |      0.152G  |
|    net_t.blocks.10                |    1.774M              |    0.456G    |
|     net_t.blocks.10.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm1.weight |      (384,)            |              |
|      net_t.blocks.10.norm1.bias   |      (384,)            |              |
|     net_t.blocks.10.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.10.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.10.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.10.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.10.norm2.weight |      (384,)            |              |
|      net_t.blocks.10.norm2.bias   |      (384,)            |              |
|     net_t.blocks.10.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.10.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.10.mlp.fc2      |      0.59M             |      0.152G  |
|    net_t.blocks.11                |    1.774M              |    0.456G    |
|     net_t.blocks.11.norm1         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm1.weight |      (384,)            |              |
|      net_t.blocks.11.norm1.bias   |      (384,)            |              |
|     net_t.blocks.11.attn          |     0.591M             |     0.152G   |
|      net_t.blocks.11.attn.qkv     |      0.444M            |      0.114G  |
|      net_t.blocks.11.attn.proj    |      0.148M            |      37.896M |
|     net_t.blocks.11.norm2         |     0.768K             |     0.493M   |
|      net_t.blocks.11.norm2.weight |      (384,)            |              |
|      net_t.blocks.11.norm2.bias   |      (384,)            |              |
|     net_t.blocks.11.mlp           |     1.182M             |     0.303G   |
|      net_t.blocks.11.mlp.fc1      |      0.591M            |      0.152G  |
|      net_t.blocks.11.mlp.fc2      |      0.59M             |      0.152G  |
|   net_t.norm                      |   0.768K               |              |
|    net_t.norm.weight              |    (384,)              |              |
|    net_t.norm.bias                |    (384,)              |              |
|  net_fusion.fc                    |  0.148M                |  37.749M     |
|   net_fusion.fc.weight            |   (384, 384)           |              |
|   net_fusion.fc.bias              |   (384,)               |              |
|  net_s                            |  16.75M                |  4.086G      |
|   net_s.cls_token                 |   (1, 1, 384)          |              |
|   net_s.pos_embed                 |   (1, 256, 384)        |              |
|   net_s.patch_embed.proj          |   0.295M               |              |
|    net_s.patch_embed.proj.weight  |    (384, 3, 16, 16)    |              |
|    net_s.patch_embed.proj.bias    |    (384,)              |              |
|   net_s.blocks                    |   15.97M               |   4.086G     |
|    net_s.blocks.0                 |    1.774M              |    0.454G    |
|     net_s.blocks.0.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm1.weight  |      (384,)            |              |
|      net_s.blocks.0.norm1.bias    |      (384,)            |              |
|     net_s.blocks.0.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.0.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.0.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.0.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.0.norm2.weight  |      (384,)            |              |
|      net_s.blocks.0.norm2.bias    |      (384,)            |              |
|     net_s.blocks.0.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.0.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.0.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.1                 |    1.774M              |    0.454G    |
|     net_s.blocks.1.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm1.weight  |      (384,)            |              |
|      net_s.blocks.1.norm1.bias    |      (384,)            |              |
|     net_s.blocks.1.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.1.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.1.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.1.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.1.norm2.weight  |      (384,)            |              |
|      net_s.blocks.1.norm2.bias    |      (384,)            |              |
|     net_s.blocks.1.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.1.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.1.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.2                 |    1.774M              |    0.454G    |
|     net_s.blocks.2.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm1.weight  |      (384,)            |              |
|      net_s.blocks.2.norm1.bias    |      (384,)            |              |
|     net_s.blocks.2.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.2.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.2.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.2.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.2.norm2.weight  |      (384,)            |              |
|      net_s.blocks.2.norm2.bias    |      (384,)            |              |
|     net_s.blocks.2.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.2.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.2.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.3                 |    1.774M              |    0.454G    |
|     net_s.blocks.3.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm1.weight  |      (384,)            |              |
|      net_s.blocks.3.norm1.bias    |      (384,)            |              |
|     net_s.blocks.3.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.3.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.3.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.3.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.3.norm2.weight  |      (384,)            |              |
|      net_s.blocks.3.norm2.bias    |      (384,)            |              |
|     net_s.blocks.3.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.3.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.3.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.4                 |    1.774M              |    0.454G    |
|     net_s.blocks.4.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm1.weight  |      (384,)            |              |
|      net_s.blocks.4.norm1.bias    |      (384,)            |              |
|     net_s.blocks.4.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.4.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.4.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.4.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.4.norm2.weight  |      (384,)            |              |
|      net_s.blocks.4.norm2.bias    |      (384,)            |              |
|     net_s.blocks.4.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.4.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.4.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.5                 |    1.774M              |    0.454G    |
|     net_s.blocks.5.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm1.weight  |      (384,)            |              |
|      net_s.blocks.5.norm1.bias    |      (384,)            |              |
|     net_s.blocks.5.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.5.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.5.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.5.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.5.norm2.weight  |      (384,)            |              |
|      net_s.blocks.5.norm2.bias    |      (384,)            |              |
|     net_s.blocks.5.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.5.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.5.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.6                 |    1.774M              |    0.454G    |
|     net_s.blocks.6.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm1.weight  |      (384,)            |              |
|      net_s.blocks.6.norm1.bias    |      (384,)            |              |
|     net_s.blocks.6.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.6.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.6.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.6.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.6.norm2.weight  |      (384,)            |              |
|      net_s.blocks.6.norm2.bias    |      (384,)            |              |
|     net_s.blocks.6.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.6.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.6.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.7                 |    1.774M              |    0.454G    |
|     net_s.blocks.7.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm1.weight  |      (384,)            |              |
|      net_s.blocks.7.norm1.bias    |      (384,)            |              |
|     net_s.blocks.7.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.7.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.7.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.7.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.7.norm2.weight  |      (384,)            |              |
|      net_s.blocks.7.norm2.bias    |      (384,)            |              |
|     net_s.blocks.7.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.7.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.7.mlp.fc2       |      0.59M             |      0.151G  |
|    net_s.blocks.8                 |    1.774M              |    0.454G    |
|     net_s.blocks.8.norm1          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm1.weight  |      (384,)            |              |
|      net_s.blocks.8.norm1.bias    |      (384,)            |              |
|     net_s.blocks.8.attn           |     0.591M             |     0.151G   |
|      net_s.blocks.8.attn.qkv      |      0.444M            |      0.113G  |
|      net_s.blocks.8.attn.proj     |      0.148M            |      37.749M |
|     net_s.blocks.8.norm2          |     0.768K             |     0.492M   |
|      net_s.blocks.8.norm2.weight  |      (384,)            |              |
|      net_s.blocks.8.norm2.bias    |      (384,)            |              |
|     net_s.blocks.8.mlp            |     1.182M             |     0.302G   |
|      net_s.blocks.8.mlp.fc1       |      0.591M            |      0.151G  |
|      net_s.blocks.8.mlp.fc2       |      0.59M             |      0.151G  |
|   net_s.norm                      |   0.768K               |              |
|    net_s.norm.weight              |    (384,)              |              |
|    net_s.norm.bias                |    (384,)              |              |
|   net_s.head                      |   0.385M               |              |
|    net_s.head.weight              |    (1000, 384)         |              |
|    net_s.head.bias                |    (1000,)             |              |
-------------------------------------------------------------------------------
2024-09-23 15:24:18,409 - ==> Creating optimizer
2024-09-23 15:24:18,411 - ==> Loading dataset: DefaultAD
2024-09-23 15:24:18,419 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 300                                 
metrics                              : ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUPRO_px', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mF1_px_0.2_0.8_0.1', 'mAcc_px_0.2_0.8_0.1', 'mIoU_px_0.2_0.8_0.1', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100}
vis                                  : False                               
vis_dir                              : None                                
optim.lr                             : 0.0001                              
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : ViTADTrainer                        
trainer.checkpoint                   : runs                                
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 300                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 1e-06, 'warmup_lr': 1.0000000000000001e-07, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 240, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 300                                 
trainer.test_per_epoch               : 30                                  
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : none                                
trainer.data.batch_size              : 8                                   
trainer.data.batch_size_per_gpu      : 8                                   
trainer.data.batch_size_test         : 8                                   
trainer.data.batch_size_per_gpu_test : 8                                   
trainer.data.num_workers_per_gpu     : 4                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 4                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 71100                               
trainer.metric_recorder              : {'mAUROC_sp_max_road': [], 'mAP_sp_max_road': [], 'mF1_max_sp_max_road': [], 'mAUPRO_px_road': [], 'mAUROC_px_road': [], 'mAP_px_road': [], 'mF1_max_px_road': [], 'mF1_px_0.2_0.8_0.1_road': [], 'mAcc_px_0.2_0.8_0.1_road': [], 'mIoU_px_0.2_0.8_0.1_road': [], 'mIoU_max_px_road': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : DefaultAD                           
data.root                            : data/mvtec                          
data.meta                            : meta.json                           
data.cls_names                       : []                                  
data.train_transforms                : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'Resize', 'size': (256, 256), 'interpolation': <InterpolationMode.BILINEAR: 'bilinear'>}, {'type': 'CenterCrop', 'size': (256, 256)}, {'type': 'ToTensor'}]
data.train_size                      : 237                                 
data.test_size                       : 184                                 
data.train_length                    : 1896                                
data.test_length                     : 1472                                
model_t.name                         : vit_small_patch16_224_dino          
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}
model_f.name                         : fusion                              
model_f.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}
model_s.name                         : de_vit_small_patch16_224_dino       
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9}
model.name                           : vitad                               
model.kwargs                         : {'pretrained': False, 'checkpoint_path': '/data/x2/ader/runs/ViTADTrainer_configs_vitad_vitad_mvtec_20240923-113201/net.pth', 'strict': True, 'model_t': Namespace(name='vit_small_patch16_224_dino', kwargs={'pretrained': True, 'checkpoint_path': '', 'pretrained_strict': False, 'strict': True, 'img_size': 256, 'teachers': [3, 6, 9], 'neck': [12]}), 'model_f': Namespace(name='fusion', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'dim': 384, 'mul': 1}), 'model_s': Namespace(name='de_vit_small_patch16_224_dino', kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False, 'img_size': 256, 'students': [3, 6, 9], 'depth': 9})}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 300                                 
test_per_epoch                       : 30                                  
batch_train                          : 8                                   
batch_test_per                       : 8                                   
lr                                   : 0.0001                              
weight_decay                         : 0.0001                              
cfg_path                             : configs.vitad.vitad_mvtec           
mode                                 : test                                
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : []                                  
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.vitad.vitad_mvtec -m test --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 
task_start_time                      : 1824185.049059067                   
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/ViTADTrainer_configs_vitad_vitad_mvtec_20240923-152417
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/ViTADTrainer_configs_vitad_vitad_mvtec_20240923-152417/show_train
logdir_test                          : runs/ViTADTrainer_configs_vitad_vitad_mvtec_20240923-152417/show_test
2024-09-23 15:24:18,419 - ==> Starting testing with 1 nodes x 1 GPUs
2024-09-23 15:24:20,834 - Test: 27.17% [50/184] [batch_t 0.048 (0.046)] [cos 0.232 (0.248)]
2024-09-23 15:24:23,058 - Test: 54.35% [100/184] [batch_t 0.064 (0.045)] [cos 0.266 (0.240)]
2024-09-23 15:24:25,118 - Test: 81.52% [150/184] [batch_t 0.067 (0.044)] [cos 0.184 (0.241)]
2024-09-23 15:24:26,455 - Test: 100.00% [184/184] [batch_t 0.037 (0.043)] [cos 0.194 (0.231)]
2024-09-23 15:28:38,210 - ==> Metric Time for road           :   0.003 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.001 (mF1_max_sp_max)	161.548 (mAUPRO_px)	 36.424 (mAUROC_px)	 29.761 (mAP_px)	  5.993 (mF1_max_px)	  2.076 (mF1_px_0.2_0.8_0.1)	  2.033 (mAcc_px_0.2_0.8_0.1)	  2.039 (mIoU_px_0.2_0.8_0.1)	  5.953 (mIoU_max_px)	
2024-09-23 15:28:38,248 - 
|  Name  |  mAUROC_sp_max  |  mAUROC_sp_max (Max)  |  mAP_sp_max  |  mAP_sp_max (Max)  |  mF1_max_sp_max  |  mF1_max_sp_max (Max)  |  mAUPRO_px  |  mAUPRO_px (Max)   |  mAUROC_px  |  mAUROC_px (Max)   |  mAP_px  |    mAP_px (Max)    |  mF1_max_px  |  mF1_max_px (Max)  |  mF1_px_0.2_0.8_0.1  |  mF1_px_0.2_0.8_0.1 (Max)  |  mAcc_px_0.2_0.8_0.1  |  mAcc_px_0.2_0.8_0.1 (Max)  |  mIoU_px_0.2_0.8_0.1  |  mIoU_px_0.2_0.8_0.1 (Max)  |  mIoU_max_px  |  mIoU_max_px (Max)  |
|:------:|:---------------:|:---------------------:|:------------:|:------------------:|:----------------:|:----------------------:|:-----------:|:------------------:|:-----------:|:------------------:|:--------:|:------------------:|:------------:|:------------------:|:--------------------:|:--------------------------:|:---------------------:|:---------------------------:|:---------------------:|:---------------------------:|:-------------:|:-------------------:|
|  road  |     93.701      |  93.701 (1   epoch)   |    98.032    | 98.032 (1   epoch) |      92.375      |   92.375 (1   epoch)   |   58.062    | 58.062 (1   epoch) |   89.727    | 89.727 (1   epoch) |  32.700  | 32.700 (1   epoch) |    38.977    | 38.977 (1   epoch) |        12.140        |     12.140 (1   epoch)     |        14.543         |     14.543 (1   epoch)      |         7.221         |      7.221 (1   epoch)      |    24.205     | 24.205 (1   epoch)  |
